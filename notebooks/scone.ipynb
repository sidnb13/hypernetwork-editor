{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "import datasets\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../assets/data/scone/rlong\"\n",
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "tasks = [\"alchemy\", \"scene\", \"tangrams\"]\n",
    "\n",
    "\n",
    "def tsv_to_dict_of_lists(file_path):\n",
    "    with open(file_path, \"r\", newline=\"\") as tsv_file:\n",
    "        reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "        # Read the first row to determine the number of columns\n",
    "        first_row = next(reader)\n",
    "        num_columns = len(first_row)\n",
    "\n",
    "        # Generate headers\n",
    "        headers = [\"ID\", \"WORLD_0\"]\n",
    "        for i in range(1, (num_columns - 2) // 2 + 1):\n",
    "            headers.extend([f\"UTTERANCE_{i}\", f\"WORLD_{i}\"])\n",
    "\n",
    "        # Create a dictionary to store the lists\n",
    "        result_dict = {header: [] for header in headers}\n",
    "\n",
    "        # Reset the file pointer to the beginning\n",
    "        tsv_file.seek(0)\n",
    "\n",
    "        # Process each row\n",
    "        for row in reader:\n",
    "            for i, value in enumerate(row):\n",
    "                if i < len(headers):\n",
    "                    result_dict[headers[i]].append(value)\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "task_datasets = defaultdict(list)\n",
    "\n",
    "for split in splits:\n",
    "    for task in tasks:\n",
    "        ds = datasets.Dataset.from_dict(\n",
    "            tsv_to_dict_of_lists(f\"{data_path}/{task}-{split}.tsv\")\n",
    "        )\n",
    "        ds = ds.add_column(\"task\", [task] * len(ds))\n",
    "        task_datasets[split].append(ds)\n",
    "\n",
    "for split, ds_list in task_datasets.items():\n",
    "    task_datasets[split] = datasets.concatenate_datasets(ds_list)\n",
    "\n",
    "scone_dataset = datasets.DatasetDict(task_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping from number to word\n",
    "num2word = {\n",
    "    1: \"first\",\n",
    "    2: \"second\",\n",
    "    3: \"third\",\n",
    "    4: \"fourth\",\n",
    "    5: \"fifth\",\n",
    "    6: \"sixth\",\n",
    "    7: \"seventh\",\n",
    "}\n",
    "color = {\n",
    "    \"g\": \"green\",\n",
    "    \"b\": \"blue\",\n",
    "    \"r\": \"red\",\n",
    "    \"y\": \"yellow\",\n",
    "    \"p\": \"purple\",\n",
    "    \"o\": \"orange\",\n",
    "}\n",
    "\n",
    "\n",
    "def alchemy_state_to_nl(state: str):\n",
    "    beakers = list(map(lambda x: (x[0], x[-1]), state.split(\" \")))\n",
    "\n",
    "    def to_nl(x):\n",
    "        i, s = x\n",
    "        if s[1] == \"_\":\n",
    "            return f\"the {num2word[i + 1]} beaker is empty\"\n",
    "        return f\"the {num2word[i + 1]} beaker has {s[0]} {color[s[1]]}\"\n",
    "\n",
    "    return \", \".join(map(to_nl, enumerate(beakers)))\n",
    "\n",
    "\n",
    "def alchemy_sequence_to_instruction(example: dict, turn_limit: int):\n",
    "    assert turn_limit <= 5, \"Alchemy only has 5 turns\"\n",
    "    world_states = [alchemy_state_to_nl(example[f\"WORLD_{i}\"]) for i in range(0, 6)]\n",
    "    utterances = [example[f\"UTTERANCE_{i}\"] for i in range(1, 6)]\n",
    "    utterances.insert(0, \"\")\n",
    "    utterances.append(\"\")\n",
    "\n",
    "    instructions = []\n",
    "    output = []\n",
    "\n",
    "    for i, state in enumerate(world_states):\n",
    "        utterance = utterances[i + 1]\n",
    "        if i + 1 <= turn_limit:\n",
    "            instructions.append(f\"{state}\\n{utterance}\".strip())\n",
    "        else:\n",
    "            output = state\n",
    "            break\n",
    "\n",
    "    return \"\\n\".join(instructions), output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 'train-A9164',\n",
       " 'WORLD_0': '1:ggg 2:_ 3:_ 4:_ 5:o 6:ooo 7:gggg',\n",
       " 'UTTERANCE_1': 'throw out two units of first beaker',\n",
       " 'WORLD_1': '1:g 2:_ 3:_ 4:_ 5:o 6:ooo 7:gggg',\n",
       " 'UTTERANCE_2': 'throw out fifth beaker',\n",
       " 'WORLD_2': '1:g 2:_ 3:_ 4:_ 5:_ 6:ooo 7:gggg',\n",
       " 'UTTERANCE_3': 'throw out first one',\n",
       " 'WORLD_3': '1:_ 2:_ 3:_ 4:_ 5:_ 6:ooo 7:gggg',\n",
       " 'UTTERANCE_4': 'throw out orange beaker',\n",
       " 'WORLD_4': '1:_ 2:_ 3:_ 4:_ 5:_ 6:_ 7:gggg',\n",
       " 'UTTERANCE_5': 'throw out one unit of green',\n",
       " 'WORLD_5': '1:_ 2:_ 3:_ 4:_ 5:_ 6:_ 7:ggg',\n",
       " 'task': 'alchemy'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scone_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first beaker has 1 green, the second beaker is empty, the third beaker is empty, the fourth beaker is empty, the fifth beaker has 5 orange, the sixth beaker has 6 orange, the seventh beaker has 7 green\n",
      "throw out two units of first beaker\n",
      "the first beaker has 1 green, the second beaker is empty, the third beaker is empty, the fourth beaker is empty, the fifth beaker has 5 orange, the sixth beaker has 6 orange, the seventh beaker has 7 green\n",
      "throw out fifth beaker\n",
      "the first beaker has 1 green, the second beaker is empty, the third beaker is empty, the fourth beaker is empty, the fifth beaker is empty, the sixth beaker has 6 orange, the seventh beaker has 7 green\n",
      "throw out first one\n",
      "================================================================================\n",
      "the first beaker is empty, the second beaker is empty, the third beaker is empty, the fourth beaker is empty, the fifth beaker is empty, the sixth beaker has 6 orange, the seventh beaker has 7 green\n"
     ]
    }
   ],
   "source": [
    "instr, output = alchemy_sequence_to_instruction(scone_dataset[\"train\"][0], 3)\n",
    "\n",
    "print(instr)\n",
    "print(\"=\" * 80)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49536a29c5b477799cf13930ef7b55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed2e943f4ee40d89815d3d6e9889fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/642 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28a3c9c4de64325b12131b8ccecae52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2734 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'WORLD_0', 'UTTERANCE_1', 'WORLD_1', 'UTTERANCE_2', 'WORLD_2', 'UTTERANCE_3', 'WORLD_3', 'UTTERANCE_4', 'WORLD_4', 'UTTERANCE_5', 'WORLD_5', 'task'],\n",
       "        num_rows: 3657\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['ID', 'WORLD_0', 'UTTERANCE_1', 'WORLD_1', 'UTTERANCE_2', 'WORLD_2', 'UTTERANCE_3', 'WORLD_3', 'UTTERANCE_4', 'WORLD_4', 'UTTERANCE_5', 'WORLD_5', 'task'],\n",
       "        num_rows: 245\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'WORLD_0', 'UTTERANCE_1', 'WORLD_1', 'UTTERANCE_2', 'WORLD_2', 'UTTERANCE_3', 'WORLD_3', 'UTTERANCE_4', 'WORLD_4', 'UTTERANCE_5', 'WORLD_5', 'task'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scone_dataset.filter(lambda x: x[\"task\"] == \"alchemy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(\"cuda\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def generate_text(prompt, max_new_tokens=100):\n",
    "    # Load pre-trained model and tokenizer\n",
    "    # Encode the input prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate text\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(\n",
    "        output[0][input_ids.shape[1] :], skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/envs/editor/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/sid/miniconda3/envs/editor/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "instr, out = alchemy_sequence_to_instruction(scone_dataset[\"train\"][0], 3)\n",
    "result = generate_text(instr, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " unit of second unit\n",
      "The first unit has 2 green and the other one has 3 orange.\n",
      "Throw out one of the units with the first green. The second one with 2 orange and one orange has 4 green but the orange with 3 green is not green so the green with 4 orange is green instead of orange\n",
      "If the unit with green has a green unit, throw out the one that has orange but not orange because the Orange with orange unit is orange instead. If the Green with Orange unit\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
