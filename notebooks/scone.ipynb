{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import datasets\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../assets/data/scone/rlong\"\n",
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "tasks = [\"alchemy\", \"scene\", \"tangrams\"]\n",
    "\n",
    "\n",
    "def tsv_to_dict_of_lists(file_path):\n",
    "    with open(file_path, \"r\", newline=\"\") as tsv_file:\n",
    "        reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "        # Read the first row to determine the number of columns\n",
    "        first_row = next(reader)\n",
    "        num_columns = len(first_row)\n",
    "\n",
    "        # Generate headers\n",
    "        headers = [\"ID\", \"WORLD_0\"]\n",
    "        for i in range(1, (num_columns - 2) // 2 + 1):\n",
    "            headers.extend([f\"UTTERANCE_{i}\", f\"WORLD_{i}\"])\n",
    "\n",
    "        # Create a dictionary to store the lists\n",
    "        result_dict = {header: [] for header in headers}\n",
    "\n",
    "        # Reset the file pointer to the beginning\n",
    "        tsv_file.seek(0)\n",
    "\n",
    "        # Process each row\n",
    "        for row in reader:\n",
    "            for i, value in enumerate(row):\n",
    "                if i < len(headers):\n",
    "                    result_dict[headers[i]].append(value)\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "task_datasets = defaultdict(list)\n",
    "\n",
    "for split in splits:\n",
    "    for task in tasks:\n",
    "        ds = datasets.Dataset.from_dict(\n",
    "            tsv_to_dict_of_lists(f\"{data_path}/{task}-{split}.tsv\")\n",
    "        )\n",
    "        ds = ds.add_column(\"task\", [task] * len(ds))\n",
    "        task_datasets[split].append(ds)\n",
    "\n",
    "for split, ds_list in task_datasets.items():\n",
    "    task_datasets[split] = datasets.concatenate_datasets(ds_list)\n",
    "\n",
    "scone_dataset = datasets.DatasetDict(task_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a363df194b254fc89f4a9b296a0d604f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1339c2b0ff94d8289870ff250a95365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/642 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91821b1788124b199c18f26a9071c26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2734 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99c8f2d6f86446f9cfe924398e10292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dfcb73431e403885b46c693f73881a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/642 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f51bd3530ef4b6880b3a327d2359b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2734 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277b756b715d4d7dbe5feac9966c7004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb684c7f538450d9eb47276d5f02b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/642 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d914c5d4b2bd45ec830be5057e9686c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2734 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tangrams = scone_dataset.filter(lambda x: x[\"task\"] == \"tangrams\")\n",
    "scenes = scone_dataset.filter(lambda x: x[\"task\"] == \"scene\")\n",
    "alchemy = scone_dataset.filter(lambda x: x[\"task\"] == \"alchemy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping from number to word\n",
    "from collections import Counter\n",
    "\n",
    "num2word = {\n",
    "    1: \"first\",\n",
    "    2: \"second\",\n",
    "    3: \"third\",\n",
    "    4: \"fourth\",\n",
    "    5: \"fifth\",\n",
    "    6: \"sixth\",\n",
    "    7: \"seventh\",\n",
    "    8: \"eighth\",\n",
    "    9: \"ninth\",\n",
    "    10: \"tenth\",\n",
    "}\n",
    "color_map = {\n",
    "    \"g\": \"green\",\n",
    "    \"b\": \"blue\",\n",
    "    \"r\": \"red\",\n",
    "    \"y\": \"yellow\",\n",
    "    \"p\": \"purple\",\n",
    "    \"o\": \"orange\",\n",
    "}\n",
    "\n",
    "\n",
    "def extract_index_and_number(input_string):\n",
    "    pattern = r\"^(\\d+):(.*)$\"\n",
    "    match = re.search(pattern, input_string)\n",
    "\n",
    "    if match:\n",
    "        index = match.group(1)\n",
    "        number = match.group(2)\n",
    "        return index, number\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def alchemy_state_to_nl(state: str):\n",
    "    beakers = list(map(lambda x: extract_index_and_number(x), state.split(\" \")))\n",
    "\n",
    "    def color_sequence_to_instruction(sequence):\n",
    "        # Count the occurrences of each color\n",
    "        color_counts = Counter(sequence.lower())\n",
    "        # Create a list of color instructions\n",
    "        instructions = []\n",
    "        for color, count in color_counts.items():\n",
    "            full_color_name = color_map[color]\n",
    "            instructions.append(f\"{count} {full_color_name}\")\n",
    "\n",
    "        # Join the instructions\n",
    "        if len(instructions) == 1:\n",
    "            return instructions[0]\n",
    "        else:\n",
    "            return \"{\" + \", \".join(instructions) + \"}\"\n",
    "\n",
    "    def to_nl(x):\n",
    "        i, s = x\n",
    "        if s[1] == \"_\":\n",
    "            return f\"the {num2word[i + 1]} beaker is empty\"\n",
    "        return f\"the {num2word[i + 1]} beaker has {color_sequence_to_instruction(s[1])}\"\n",
    "\n",
    "    return \", \".join(map(to_nl, enumerate(beakers)))\n",
    "\n",
    "\n",
    "def scene_state_to_nl(state: str):\n",
    "    positions = list(map(lambda x: extract_index_and_number(x), state.split(\" \")))\n",
    "\n",
    "    def to_nl(x):\n",
    "        i, s = x\n",
    "        if s[1][0] == \"_\":\n",
    "            return f\"the {num2word[i + 1]} position is empty\"\n",
    "        hat = color_map[s[1][1]] if s[1][1] != \"_\" else \"no\"\n",
    "        return f\"the {num2word[i + 1]} position is occupied by a person with a {color_map[s[1][0]]} shirt and {hat} hat\"\n",
    "\n",
    "    return \", \".join(map(to_nl, enumerate(positions)))\n",
    "\n",
    "\n",
    "def tangram_state_to_nl(state: str):\n",
    "    tangrams = list(map(lambda x: extract_index_and_number(x), state.split(\" \")))\n",
    "\n",
    "    def to_nl(x):\n",
    "        i, s = x\n",
    "        if s[1] == \"_\":\n",
    "            return f\"the {num2word[i + 1]} tangram is not placed\"\n",
    "        return f\"{num2word[i + 1]} object id={s[1]}\"\n",
    "\n",
    "    return \", \".join(map(to_nl, enumerate(tangrams)))\n",
    "\n",
    "\n",
    "def sequence_to_instruction(example: dict, turn_limit: int):\n",
    "    if example[\"task\"] == \"alchemy\":\n",
    "        nl_fn = alchemy_state_to_nl\n",
    "    elif example[\"task\"] == \"tangrams\":\n",
    "        nl_fn = tangram_state_to_nl\n",
    "    elif example[\"task\"] == \"scene\":\n",
    "        nl_fn = scene_state_to_nl\n",
    "\n",
    "    limit = len([k for k in example.keys() if k.startswith(\"WORLD_\")])\n",
    "\n",
    "    world_states = [nl_fn(example[f\"WORLD_{i}\"]) for i in range(0, limit)]\n",
    "    utterances = [example[f\"UTTERANCE_{i}\"] for i in range(1, limit)]\n",
    "    utterances.insert(0, \"\")\n",
    "    utterances.append(\"\")\n",
    "\n",
    "    instructions = []\n",
    "    output = []\n",
    "\n",
    "    for i, state in enumerate(world_states):\n",
    "        utterance = utterances[i + 1]\n",
    "        if i + 1 <= turn_limit:\n",
    "            instructions.append(f\"{state}\\n{utterance}\".strip())\n",
    "        else:\n",
    "            output = state\n",
    "            break\n",
    "\n",
    "    return \"\\n\".join(instructions), output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first position is empty, the second position is empty, the third position is empty, the fourth position is empty, the fifth position is empty, the sixth position is empty, the seventh position is occupied by a person with a green shirt and orange hat, the eighth position is empty, the ninth position is empty, the tenth position is occupied by a person with a yellow shirt and orange hat\n",
      "a man in a green shirt and an orange hat stands near the middle and a man in a yellow shirt and an orange hat stands on the far right\n",
      "the first position is occupied by a person with a red shirt and no hat, the second position is empty, the third position is empty, the fourth position is empty, the fifth position is empty, the sixth position is empty, the seventh position is occupied by a person with a green shirt and orange hat, the eighth position is empty, the ninth position is empty, the tenth position is occupied by a person with a yellow shirt and orange hat\n",
      "a man in a red shirt and no hat enters and stands on the far left\n",
      "the first position is occupied by a person with a red shirt and no hat, the second position is empty, the third position is empty, the fourth position is empty, the fifth position is empty, the sixth position is empty, the seventh position is occupied by a person with a green shirt and orange hat, the eighth position is empty, the ninth position is occupied by a person with a yellow shirt and no hat, the tenth position is occupied by a person with a yellow shirt and orange hat\n",
      "a man in a yellow shirt and no hat joins and stands next to the man in the yellow shirt and orange hat\n",
      "================================================================================\n",
      "the first position is occupied by a person with a red shirt and no hat, the second position is empty, the third position is empty, the fourth position is empty, the fifth position is empty, the sixth position is occupied by a person with a green shirt and orange hat, the seventh position is empty, the eighth position is empty, the ninth position is occupied by a person with a yellow shirt and no hat, the tenth position is occupied by a person with a yellow shirt and orange hat\n"
     ]
    }
   ],
   "source": [
    "instr, output = sequence_to_instruction(scenes[\"train\"][0], 3)\n",
    "\n",
    "print(instr)\n",
    "print(\"=\" * 80)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first beaker has 3 green, the second beaker is empty, the third beaker is empty, the fourth beaker is empty, the fifth beaker has 1 orange, the sixth beaker has 3 orange, the seventh beaker has 4 green\n",
      "throw out two units of first beaker\n",
      "the first beaker has 1 green, the second beaker is empty, the third beaker is empty, the fourth beaker is empty, the fifth beaker has 1 orange, the sixth beaker has 3 orange, the seventh beaker has 4 green\n",
      "throw out fifth beaker\n",
      "the first beaker has 1 green, the second beaker is empty, the third beaker is empty, the fourth beaker is empty, the fifth beaker is empty, the sixth beaker has 3 orange, the seventh beaker has 4 green\n",
      "throw out first one\n",
      "================================================================================\n",
      "the first beaker is empty, the second beaker is empty, the third beaker is empty, the fourth beaker is empty, the fifth beaker is empty, the sixth beaker has 3 orange, the seventh beaker has 4 green\n"
     ]
    }
   ],
   "source": [
    "instr, output = sequence_to_instruction(alchemy[\"train\"][0], 3)\n",
    "\n",
    "print(instr)\n",
    "print(\"=\" * 80)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first object id=2, second object id=1, third object id=4, fourth object id=0, fifth object id=3\n",
      "delete the second object from the left\n",
      "first object id=2, second object id=4, third object id=0, fourth object id=3\n",
      "delete the leftmost object\n",
      "first object id=4, second object id=0, third object id=3\n",
      "swap the leftmost and the rightmost objects\n",
      "================================================================================\n",
      "first object id=3, second object id=0, third object id=4\n"
     ]
    }
   ],
   "source": [
    "instr, output = sequence_to_instruction(tangrams[\"train\"][0], 3)\n",
    "\n",
    "print(instr)\n",
    "print(\"=\" * 80)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(\"cuda\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def generate_text(prompt, max_new_tokens=100):\n",
    "    # Load pre-trained model and tokenizer\n",
    "    # Encode the input prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate text\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(\n",
    "        output[0][input_ids.shape[1] :], skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/envs/editor/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/sid/miniconda3/envs/editor/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "instr, out = sequence_to_instruction(scone_dataset[\"train\"][0], 3)\n",
    "result = generate_text(instr, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " unit of second unit\n",
      "The first unit has 2 green and the other one has 3 orange.\n",
      "Throw out one of the units with the first green. The second one with 2 orange and one orange has 4 green but the orange with 3 green is not green so the green with 4 orange is green instead of orange\n",
      "If the unit with green has a green unit, throw out the one that has orange but not orange because the Orange with orange unit is orange instead. If the Green with Orange unit\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
